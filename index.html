<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Jian Wang</title>
  <meta name="author" content="Jian Wang" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="stylesheet.css" />
  <link rel="icon" type="image/x-icon" href="https://123publicdata.s3-ap-southeast-1.amazonaws.com/personal/favor.ico" />
  <style>
    /* Collapsible paper styles */
    .paper-container {
      border: 1px solid #e0e0e0;
      border-radius: 8px;
      margin-bottom: 20px;
      padding: 15px;
      background: #fafafa;
      transition: all 0.3s ease;
    }
    
    .paper-container:hover {
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    .paper-header {
      cursor: pointer;
      display: flex;
      align-items: flex-start;
      gap: 15px;
    }
    
    .paper-thumbnail {
      flex-shrink: 0;
      width: 120px;
      max-height: 0;
      overflow: hidden;
      opacity: 0;
      transition: max-height 0.3s ease, opacity 0.3s ease, margin-top 0.3s ease;
    }
    
    .paper-container.expanded .paper-thumbnail {
      max-height: 200px;
      opacity: 1;
      margin-top: 10px;
    }
    
    .paper-thumbnail img {
      width: 100%;
      height: auto;
      border-radius: 4px;
    }
    
    .paper-info {
      flex-grow: 1;
    }
    
    .paper-title {
      font-size: 1.1em;
      font-weight: bold;
      color: #0066cc;
      margin: 0 0 8px 0;
    }
    
    .paper-title:hover {
      text-decoration: underline;
    }
    
    .paper-authors {
      color: #555;
      margin: 5px 0;
      font-size: 0.95em;
    }

    .paper-authors a {
      color: #555;
      text-decoration: none;
    }

    .paper-authors a:hover {
      text-decoration: underline;
    }
    
    .venue-row {
      display: flex;
      align-items: flex-start;
      flex-wrap: nowrap;
      gap: 8px;
    }

    .paper-venue {
      color: #666;
      font-style: italic;
      margin: 5px 0;
      font-size: 0.9em;
    }
    
    .paper-short-desc {
      color: #444;
      margin: 10px 0 0 0;
      font-size: 0.9em;
      line-height: 1.5;
    }
    
    .expand-icon {
      color: #888;
      font-size: 1.2em;
      line-height: 1.2em;
      transition: transform 0.3s ease;
      flex-shrink: 0;
    }
    
    .paper-container.expanded .expand-icon {
      transform: rotate(180deg);
    }
    
    .paper-details {
      max-height: 0;
      overflow: hidden;
      transition: max-height 0.3s ease;
      margin-top: 15px;
    }
    
    .paper-container.expanded .paper-details {
      max-height: 2000px;
    }
    
    .detail-buttons {
      margin: 15px 0;
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
    }
    
    .detail-btn {
      padding: 6px 15px;
      background: #0066cc;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 0.9em;
      transition: background 0.2s ease;
    }
    
    .detail-btn:hover {
      background: #0052a3;
    }
    
    .detail-btn.active {
      background: #004080;
    }
    
    .detail-section {
      display: none;
      margin: 15px 0;
      padding: 15px;
      background: white;
      border-radius: 4px;
      border-left: 3px solid #0066cc;
      position: relative;
    }
    
    .detail-section.show {
      display: block;
      animation: fadeIn 0.3s ease;
    }
    
    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(-10px); }
      to { opacity: 1; transform: translateY(0); }
    }
    
    .detail-section h3 {
      margin-top: 0;
      color: #333;
      font-size: 1em;
    }
    
    .abstract-text {
      line-height: 1.6;
      color: #444;
    }

    /* Citation block and copy button */
    .citation-wrapper {
      position: relative;
    }

    .copy-btn {
      position: absolute;
      top: 0;
      right: 0;
      border: 1px solid #0066cc;
      background: #f0f8ff;
      color: #0066cc;
      border-radius: 4px;
      font-size: 0.8em;
      padding: 4px 8px;
      cursor: pointer;
      line-height: 1.2;
      display: flex;
      align-items: center;
      gap: 4px;
    }

    .copy-btn.copied {
      background: #d1ffd6;
      border-color: #1a7f37;
      color: #1a7f37;
    }

    .citation-block {
      background: #f5f5f5;
      padding: 15px;
      border-radius: 4px;
      font-family: 'Courier New', monospace;
      font-size: 0.85em;
      overflow-x: auto;
      white-space: pre-wrap;
      word-wrap: break-word;
      margin-top: 30px; /* add spacing so text doesn't sit under button */
    }
    
    .paper-links {
      display: flex;
      gap: 15px;
      flex-wrap: wrap;
      margin-top: 10px;
    }
    
    .paper-links a {
      color: #0066cc;
      text-decoration: none;
      font-weight: 500;
    }
    
    .paper-links a:hover {
      text-decoration: underline;
    }
    
    .highlight-badge {
      display: inline-block;
      background: #ffd700;
      color: #333;
      padding: 2px 8px;
      border-radius: 3px;
      font-size: 0.8em;
      font-weight: bold;
      margin-left: 5px;
    }
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
    <tbody>
      <tr>
        <td style="padding:0;">
          <!-- Header / Intro -->
          <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:2.5%;width:63%;vertical-align:middle;">
                  <p style="text-align:center;margin:0;">
                    <h1 style="margin:0;">Jian Wang (王剑)</h1>
                  </p>
                  <p>
                    Jian Wang is a Ph.D. candidate (expected Jan 2026, now at job market ) at the College of Computing and Data Science (CCDS), Nanyang Technological University (NTU), Singapore, advised by
                    <a href="https://personal.ntu.edu.sg/yi_li/">Prof. Li Yi</a>. His work focuses on code LLM security and intelligence.
                  </p>

                  <p style="text-align:center;">
                    <a href="mailto:jian004@e.ntu.edu.sg">Email</a> &nbsp;/&nbsp;
                    <a href="data/JianWang_cv.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="data/jornbowrl-bio.txt">Biography</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?hl=en&user=GAe_mJUAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                    <a href="https://twitter.com/jornbowrl">Twitter</a>
                  </p>
                </td>

                <td style="padding:2.5%;width:40%;max-width:40%;text-align:center;vertical-align:middle;">
                  <a href="images/jornbowrl2.jpg">
                    <img
                      src="https://123publicdata.s3.ap-southeast-1.amazonaws.com/personal/w.jpg"
                      alt="Jian Wang profile photo"
                      class="hoverZoomLink"
                      style="width:50%;max-width:50%;height:auto;"
                    />
                  </a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Bio -->
          <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle;">
                  <h2>Bio</h2>
                  <p>
                    Since 2019, Jian has been a research assistant at SMU (2023-Aug - present) and NTU(2020-2023 Aug). Previously, he was a researcher at Xiaomi AI Lab and a software engineer at 58.com.
                  </p>
                  <p>
                    He expects to receive his Ph.D. from NTU in 2026 and holds a B.A. in Software Engineering from Tianjin University (2011).
                  </p>
                  <p>
		  Jian's research interests lie at the intersection of Software Engineering, Large Language Models, and Trustworthy AI Systems. Using deep learning and retrieval-augmented methods as the core driving engine, I develop automated techniques for program repair and AI-generated code detection, applying them toward enhancing software reliability—from identifying untrusted AI-generated code to automatically fixing bugs in safety-critical systems. I am particularly passionate about semantically-grounded program understanding, moving beyond pattern matching to genuine reasoning about code behavior and runtime execution.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Research -->
          <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:20px;">
                  <h2>Research</h2>
                  
                  <!-- Paper 1: Defects4C -->
                  <div class="paper-container">
                    <div class="paper-header" onclick="togglePaper(this)">
                      <div class="paper-info">
                        <div class="paper-title">
                          Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs
                          <span class="highlight-badge">Featured</span>
                        </div>
                        <div class="paper-authors" onclick="event.stopPropagation();">
                          <a href="https://scholar.google.com/citations?hl=en&user=GAe_mJUAAAAJ"><strong>Jian Wang</strong></a>,
                          <a href="#">Xiaofei Xie</a>,
                          <a href="#">Qiang Hu</a>,
                          <a href="#">Shangqing Liu</a>,
                          <a href="#">Jiongchi Yu</a>,
                          <a href="#">Jiaolong Kong</a>,
                          <a href="https://personal.ntu.edu.sg/yi_li/">Yi Li</a>
                        </div>
                        <div class="venue-row">
                          <div class="paper-venue">
                            In Proceedings of the 40th IEEE/ACM International Conference on Automated Software Engineering (ASE), 2025
                          </div>
                          <span class="expand-icon">▼</span>
                        </div>
                        <div class="paper-short-desc">
                          We introduce Defects4C, a comprehensive benchmark for evaluating LLM-based automated program repair capabilities on C/C++ bugs, addressing the significant gap in C/C++ repair research.
                        </div>
                      </div>
                    </div>
                    
                    <div class="paper-thumbnail">
                      <img src="images/defects4c.png" alt="Defects4C thumbnail" onerror="this.src='data:image/svg+xml,%3Csvg xmlns=\'http://www.w3.org/2000/svg\' width=\'160\' height=\'120\'%3E%3Crect fill=\'%23ddd\' width=\'160\' height=\'120\'/%3E%3Ctext x=\'50%25\' y=\'50%25\' text-anchor=\'middle\' dy=\'.3em\' fill=\'%23999\'%3EDefects4C%3C/text%3E%3C/svg%3E'" />
                    </div>
                    
                    <div class="paper-details">
                      <div class="detail-buttons">
                        <button class="detail-btn" onclick="toggleDetail(this, 'abstract-1')">Abstract</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'cite-1')">Cite</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'links-1')">Links</button>
                      </div>
                      
                      <div id="abstract-1" class="detail-section">
                        <h3>Abstract</h3>
                        <div class="abstract-text">
                          Automated Program Repair (APR) plays a critical role in enhancing the quality and reliability of software systems. While substantial progress has been made in Java-based APR, largely facilitated by benchmarks like Defects4J, there remains a significant gap in research on C/C++ program repair, despite the widespread use of C/C++ and the prevalence of associated vulnerabilities. This paper introduces Defects4C, a comprehensive benchmark designed to evaluate and advance LLM-based automated repair techniques for C/C++ programs.
                        </div>
                      </div>
                      
                      <div id="cite-1" class="detail-section">
                        <h3>Citation</h3>
                        <div class="citation-wrapper">
                          <button class="copy-btn" data-copy-target="cite-1-text" onclick="copyCitation(event, this)">📋 Copy</button>
                          <div id="cite-1-text" class="citation-block">@inproceedings{Wang2025DBL,
  author = {Wang, Jian and Xie, Xiaofei and Hu, Qiang and Liu, Shangqing and Yu, Jiongchi and Kong, Jiaolong and Li, Yi},
  booktitle = {Proceedings of the 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  month = nov,
  title = {{Defects4C}: Benchmarking Large Language Model Repair Capability with {C/C++} Bugs},
  year = {2025}
}</div>
                        </div>
                      </div>
                      
                      <div id="links-1" class="detail-section">
                        <h3>Resources</h3>
                        <div class="paper-links">
                          <a href="https://arxiv.org/abs/2501.xxxxx" target="_blank">📄 Paper</a>
                          <a href="https://github.com/username/defects4c" target="_blank">💻 Project</a>
                          <a href="https://arxiv.org/abs/2501.xxxxx" target="_blank">📚 arXiv</a>
                        </div>
                      </div>
                    </div>
                  </div>


                  <!-- Paper 2: RATCHET -->
                  <div class="paper-container">
                    <div class="paper-header" onclick="togglePaper(this)">
                      <div class="paper-info">
                        <div class="paper-title">
                          RATCHET: Retrieval Augmented Transformer for Program Repair
                        </div>
                        <div class="paper-authors" onclick="event.stopPropagation();">
                          <a href="https://scholar.google.com/citations?hl=en&user=GAe_mJUAAAAJ"><strong>Jian Wang</strong></a>,
                          <a href="#">Shangqing Liu</a>,
                          <a href="#">Xiaofei Xie</a>,
                          <a href="#">Jing Kai Siow</a>,
                          <a href="#">Kui Liu</a>,
                          <a href="https://personal.ntu.edu.sg/yi_li/">Yi Li</a>
                        </div>
                        <div class="venue-row">
                          <div class="paper-venue">
                            In Proceedings of the 35th International Symposium on Software Reliability Engineering (ISSRE), 2024
                          </div>
                          <span class="expand-icon">▼</span>
                        </div>
                        <div class="paper-short-desc">
                          Ratchet is a dual deep-learning Automated Program Repair (APR) system with (1) Ratchet-FL for fault localization using only code (no failing tests or bug reports) and (2) Ratchet-PG for patch generation using a retrieval-augmented transformer trained on historical fixes. Ratchet outperforms prior deep learning APR approaches on both localization and repair accuracy.
                        </div>
                      </div>
                    </div>

                    <div class="paper-thumbnail">
                      <img src="images/ratchet.png"
                          alt="RATCHET APR thumbnail"
                          onerror="this.src='data:image/svg+xml,%3Csvg xmlns=\'http://www.w3.org/2000/svg\' width=\'160\' height=\'120\'%3E%3Crect fill=\'%23ddd\' width=\'160\' height=\'120\'/%3E%3Ctext x=\'50%25\' y=\'50%25\' text-anchor=\'middle\' dy=\'.3em\' fill=\'%23999\'%3ERATCHET%3C/text%3E%3C/svg%3E'" />
                    </div>

                    <div class="paper-details">
                      <div class="detail-buttons">
                        <button class="detail-btn" onclick="toggleDetail(this, 'abstract-2')">Abstract</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'cite-2')">Cite</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'links-2')">Links</button>
                      </div>

                      <div id="abstract-2" class="detail-section">
                        <h3>Abstract</h3>
                        <div class="abstract-text">
                          Automated Program Repair (APR) aims to relieve developers from manual debugging by automatically fixing bugs. Current approaches face two core challenges: (1) fault localization frequently depends on extra artifacts (e.g., failing tests, bug reports) that may not exist early in development, and (2) seq2seq-style patch generation needs high-quality contextual hints, which are hard to obtain consistently. This paper proposes Ratchet, a dual deep-learning APR framework. Ratchet-FL locates buggy statements using a BiLSTM model directly over code, without relying on bug-triggering tests or bug reports. Ratchet-PG generates candidate patches using a retrieval augmented transformer that learns from historical fixes. Evaluations on both an in-the-lab dataset (DrRepair) and an in-the-wild dataset (Ratchet-DS) show that Ratchet achieves 39.8–96.4% localization accuracy and 18.4–46.4% repair accuracy, outperforming state-of-the-art baselines.
                        </div>
                      </div>

                      <div id="cite-2" class="detail-section">
                        <h3>Citation</h3>
                        <div class="citation-wrapper">
                          <button class="copy-btn" data-copy-target="cite-2-text" onclick="copyCitation(event, this)">📋 Copy</button>
                          <div id="cite-2-text" class="citation-block">
@inproceedings{Wang2024RAT,
  author = {Wang, Jian and Liu, Shangqing and Xie, Xiaofei and Siow, Jing Kai and Liu, Kui and Li, Yi},
  booktitle = {Proceedings of the 35th International Symposium on Software Reliability Engineering (ISSRE)},
  month = oct,
  pages = {427--438},
  title = {{RATCHET}: Retrieval Augmented Transformer for Program Repair},
  year = {2024}
}
                          </div>
                        </div>
                      </div>

                      <div id="links-2" class="detail-section">
                        <h3>Resources</h3>
                        <div class="paper-links">
                          <a href="#" target="_blank">📄 Paper</a>
                          <a href="#" target="_blank">💻 Project</a>
                          <a href="#" target="_blank">📚 arXiv</a>
                        </div>
                      </div>
                    </div>
                  </div>



                  <!-- Paper 3: AIGC Detectors on Code Content -->
                  <div class="paper-container">
                    <div class="paper-header" onclick="togglePaper(this)">
                      <div class="paper-info">
                        <div class="paper-title">
                          An Empirical Study to Evaluate AIGC Detectors on Code Content
                        </div>
                        <div class="paper-authors" onclick="event.stopPropagation();">
                          <a href="https://scholar.google.com/citations?hl=en&user=GAe_mJUAAAAJ"><strong>Jian Wang</strong></a>,
                          <a href="#">Shangqing Liu</a>,
                          <a href="#">Xiaofei Xie</a>,
                          <a href="https://personal.ntu.edu.sg/yi_li/">Yi Li</a>
                        </div>
                        <div class="venue-row">
                          <div class="paper-venue">
                            In Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering (ASE), 2024
                          </div>
                          <span class="expand-icon">▼</span>
                        </div>
                        <div class="paper-short-desc">
                          This work systematically evaluates commercial and open-source AI-generated content (AIGC) detectors on code-related content from modern LLMs (GPT-3.5, WizardCoder, CodeLlama). The study reveals that detectors trained on natural language struggle with code, and that fine-tuning helps within-domain but generalization remains weak.
                        </div>
                      </div>
                    </div>

                    <div class="paper-thumbnail">
                      <img src="images/aigc-detectors.png"
                          alt="AIGC detector evaluation thumbnail"
                          onerror="this.src='data:image/svg+xml,%3Csvg xmlns=\'http://www.w3.org/2000/svg\' width=\'160\' height=\'120\'%3E%3Crect fill=\'%23ddd\' width=\'160\' height=\'120\'/%3E%3Ctext x=\'50%25\' y=\'50%25\' text-anchor=\'middle\' dy=\'.3em\' fill=\'%23999\'%3EAIGC%3C/text%3E%3C/svg%3E'" />
                    </div>

                    <div class="paper-details">
                      <div class="detail-buttons">
                        <button class="detail-btn" onclick="toggleDetail(this, 'abstract-3')">Abstract</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'cite-3')">Cite</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'links-3')">Links</button>
                      </div>

                      <div id="abstract-3" class="detail-section">
                        <h3>Abstract</h3>
                        <div class="abstract-text">
                          Large language models (LLMs) like ChatGPT can generate high-quality code, summaries, and Q&amp;A-style responses for software tasks. This creates both productivity benefits and new risks, including academic dishonesty and unvetted code in safety-critical settings. While many AIGC detectors have been introduced and benchmarked on natural language prose, their robustness on programming-related content is unclear. This paper conducts the first large-scale evaluation of thirteen AIGC detectors — six commercial and seven open source — on code-oriented outputs from GPT-3.5, WizardCoder, and CodeLlama. We build a dataset of 2.23M samples spanning Q&amp;A (150K), code summarization (1M), and code generation (1.1M). Results show that current detectors generally underperform on code compared to natural language, and although fine-tuning improves within-domain detection, cross-domain generalization remains challenging.
                        </div>
                      </div>

                      <div id="cite-3" class="detail-section">
                        <h3>Citation</h3>
                        <div class="citation-wrapper">
                          <button class="copy-btn" data-copy-target="cite-3-text" onclick="copyCitation(event, this)">📋 Copy</button>
                          <div id="cite-3-text" class="citation-block">
@inproceedings{Wang2024AES,
  author = {Wang, Jian and Liu, Shangqing and Xie, Xiaofei and Li, Yi},
  booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  month = oct,
  pages = {844--856},
  title = {An Empirical Study to Evaluate {AIGC} Detectors on Code Content},
  year = {2024}
}
                          </div>
                        </div>
                      </div>

                      <div id="links-3" class="detail-section">
                        <h3>Resources</h3>
                        <div class="paper-links">
                          <a href="#" target="_blank">📄 Paper</a>
                          <a href="#" target="_blank">📚 arXiv</a>
                        </div>
                      </div>
                    </div>
                  </div>



                  <!-- Paper 4: Do Code Semantics Help? -->
                  <div class="paper-container">
                    <div class="paper-header" onclick="togglePaper(this)">
                      <div class="paper-info">
                        <div class="paper-title">
                          Do Code Semantics Help? A Comprehensive Study on Execution Trace-Based Information for Code Large Language Models
                        </div>
                        <div class="paper-authors" onclick="event.stopPropagation();">
                          <a href="https://scholar.google.com/citations?hl=en&user=GAe_mJUAAAAJ"><strong>Jian Wang</strong></a>,
                          <a href="#">Xiaofei Xie</a>,
                          <a href="#">Qiang Hu</a>,
                          <a href="#">Shangqing Liu</a>,
                          <a href="https://personal.ntu.edu.sg/yi_li/">Yi Li</a>
                        </div>
                        <div class="venue-row">
                          <div class="paper-venue">
                            In Findings of the Association for Computational Linguistics: EMNLP, 2025
                          </div>
                          <span class="expand-icon">▼</span>
                        </div>
                        <div class="paper-short-desc">
                          This paper investigates whether enriching prompts or training signals with semantic/runtime information (like execution traces) actually improves Code LLM reasoning. The study proposes a generic framework for injecting such semantics into both supervised fine-tuning and inference-time prompting, and finds that — contrary to prior claims — the gains are often limited.
                        </div>
                      </div>
                    </div>

                    <div class="paper-thumbnail">
                      <img src="images/code-semantics.png"
                          alt="Code semantics / execution traces thumbnail"
                          onerror="this.src='data:image/svg+xml,%3Csvg xmlns=\'http://www.w3.org/2000/svg\' width=\'160\' height=\'120\'%3E%3Crect fill=\'%23ddd\' width=\'160\' height=\'120\'/%3E%3Ctext x=\'50%25\' y=\'50%25\' text-anchor=\'middle\' dy=\'.3em\' fill=\'%23999\'%3ETrace Study%3C/text%3E%3C/svg%3E'" />
                    </div>

                    <div class="paper-details">
                      <div class="detail-buttons">
                        <button class="detail-btn" onclick="toggleDetail(this, 'abstract-4')">Abstract</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'cite-4')">Cite</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'links-4')">Links</button>
                      </div>

                      <div id="abstract-4" class="detail-section">
                        <h3>Abstract</h3>
                        <div class="abstract-text">
                          Code Large Language Models (Code LLMs) have shown impressive capabilities but still struggle to deeply reason about runtime behavior and actual program functionality. We identify two key challenges: (1) weak reasoning over program execution, and (2) inconsistent ways of representing semantic signals like execution traces, which hurts generalization. We propose a general framework for integrating semantic, trace-based information into prompts for code tasks, and we conduct a broad empirical study examining how such information affects both supervised fine-tuning (SFT) and test-time inference (post-training prompting). Surprisingly, our results challenge prior optimism: execution-trace semantic signals offer only limited benefits for SFT and test-time scaling of Code LLMs, suggesting that naive “just add traces” strategies are not enough to close LLM reasoning gaps.
                        </div>
                      </div>

                      <div id="cite-4" class="detail-section">
                        <h3>Citation</h3>
                        <div class="citation-wrapper">
                          <button class="copy-btn" data-copy-target="cite-4-text" onclick="copyCitation(event, this)">📋 Copy</button>
                          <div id="cite-4-text" class="citation-block">
@inproceedings{Wang2025DCS,
  author = {Wang, Jian and Xie, Xiaofei and Hu, Qiang and Liu, Shangqing and Li, Yi},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP},
  month = nov,
  title = {Do Code Semantics Help? A Comprehensive Study on Execution Trace-Based Information for Code Large Language Models},
  year = {2025}
}
                          </div>
                        </div>
                      </div>

                      <div id="links-4" class="detail-section">
                        <h3>Resources</h3>
                        <div class="paper-links">
                          <a href="#" target="_blank">📄 Paper</a>
                          <a href="#" target="_blank">📚 arXiv</a>
                        </div>
                      </div>
                    </div>
                  </div>



                  <!-- Paper 5: Enhancing Code Vulnerability Detection -->
                  <div class="paper-container">
                    <div class="paper-header" onclick="togglePaper(this)">
                      <div class="paper-info">
                        <div class="paper-title">
                          Enhancing Code Vulnerability Detection via Vulnerability-Preserving Data Augmentation
                        </div>
                        <div class="paper-authors" onclick="event.stopPropagation();">
                          <a href="#">Shangqing Liu</a>,
                          <a href="#">Wei Ma</a>,
                          <a href="https://scholar.google.com/citations?hl=en&user=GAe_mJUAAAAJ"><strong>Jian Wang</strong></a>,
                          <a href="#">Xiaofei Xie</a>,
                          <a href="#">Ruitao Feng</a>,
                          <a href="#">Yang Liu</a>
                        </div>
                        <div class="venue-row">
                          <div class="paper-venue">
                            Proceedings of the ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES), 2024
                          </div>
                          <span class="expand-icon">▼</span>
                        </div>
                        <div class="paper-short-desc">
                          The authors propose FGVulDet, a fine-grained vulnerability detector that uses multiple classifiers to identify specific vulnerability types, plus a novel vulnerability-preserving data augmentation strategy to combat data scarcity. An edge-aware GGNN model captures rich code semantics and improves generalization.
                        </div>
                      </div>
                    </div>

                    <div class="paper-thumbnail">
                      <img src="images/fgvuldet.png"
                          alt="FGVulDet vulnerability detection thumbnail"
                          onerror="this.src='data:image/svg+xml,%3Csvg xmlns=\'http://www.w3.org/2000/svg\' width=\'160\' height=\'120\'%3E%3Crect fill=\'%23ddd\' width=\'160\' height=\'120\'/%3E%3Ctext x=\'50%25\' y=\'50%25\' text-anchor=\'middle\' dy=\'.3em\' fill=\'%23999\'%3EFGVulDet%3C/text%3E%3C/svg%3E'" />
                    </div>

                    <div class="paper-details">
                      <div class="detail-buttons">
                        <button class="detail-btn" onclick="toggleDetail(this, 'abstract-6')">Abstract</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'cite-6')">Cite</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'links-6')">Links</button>
                      </div>

                      <div id="abstract-6" class="detail-section">
                        <h3>Abstract</h3>
                        <div class="abstract-text">
                          Source code vulnerability detection aims to surface exploitable weaknesses before attackers can abuse them. Many prior methods reduce this task to binary classification (vulnerable vs. not vulnerable), which ignores the diversity of vulnerability types and limits model generalization — especially under limited training data. This work introduces FGVulDet, a fine-grained vulnerability detector that (1) trains specialized classifiers for different vulnerability types and fuses them to infer the specific vulnerability category, and (2) performs vulnerability-preserving data augmentation to improve coverage for underrepresented classes. Building on recent advances in code representation via graph neural networks, we adapt and extend a Gated Graph Neural Network (GGNN) into an edge-aware GGNN that incorporates edge-type information. Trained on a large GitHub-derived dataset spanning five vulnerability types, FGVulDet outperforms both static-analysis-based and learning-based baselines.
                        </div>
                      </div>

                      <div id="cite-6" class="detail-section">
                        <h3>Citation</h3>
                        <div class="citation-wrapper">
                          <button class="copy-btn" data-copy-target="cite-6-text" onclick="copyCitation(event, this)">📋 Copy</button>
                          <div id="cite-6-text" class="citation-block">
@inproceedings{liu2024enhancing,
  title={Enhancing code vulnerability detection via vulnerability-preserving data augmentation},
  author={Liu, Shangqing and Ma, Wei and Wang, Jian and Xie, Xiaofei and Feng, Ruitao and Liu, Yang},
  booktitle={Proceedings of the 25th ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems},
  pages={166--177},
  year={2024}
}
                          </div>
                        </div>
                      </div>

                      <div id="links-6" class="detail-section">
                        <h3>Resources</h3>
                        <div class="paper-links">
                          <a href="#" target="_blank">📄 Paper</a>
                          <a href="#" target="_blank">📚 arXiv</a>
                        </div>
                      </div>
                    </div>
                  </div>



                  <!-- Paper 6: Faire (Fairness Repair) -->
                  <div class="paper-container">
                    <div class="paper-header" onclick="togglePaper(this)">
                      <div class="paper-info">
                        <div class="paper-title">
                          Faire: Repairing Fairness of Neural Networks via Neuron Condition Synthesis
                        </div>
                        <div class="paper-authors" onclick="event.stopPropagation();">
                          <a href="#">Tianlin Li</a>,
                          <a href="#">Xiaofei Xie</a>,
                          <a href="https://scholar.google.com/citations?hl=en&user=GAe_mJUAAAAJ"><strong>Jian Wang</strong></a>,
                          <a href="#">Qing Guo</a>,
                          <a href="#">Aishan Liu</a>,
                          <a href="#">Lei Ma</a>,
                          <a href="#">Yang Liu</a>
                        </div>
                        <div class="venue-row">
                          <div class="paper-venue">
                            ACM Transactions on Software Engineering and Methodology (TOSEM)
                          </div>
                          <span class="expand-icon">▼</span>
                        </div>
                        <div class="paper-short-desc">
                          Faire repairs unfair behavior in DNNs by identifying neurons linked to protected attributes and inserting new “condition layers” that penalize biased neurons and reward task-relevant ones — achieving &gt;99% repair rate without requiring extra discriminatory examples.
                        </div>
                      </div>
                    </div>

                    <div class="paper-thumbnail">
                      <img src="images/faire.png"
                          alt="Faire fairness repair thumbnail"
                          onerror="this.src='data:image/svg+xml,%3Csvg xmlns=\'http://www.w3.org/2000/svg\' width=\'160\' height=\'120\'%3E%3Crect fill=\'%23ddd\' width=\'160\' height=\'120\'/%3E%3Ctext x=\'50%25\' y=\'50%25\' text-anchor=\'middle\' dy=\'.3em\' fill=\'%23999\'%3EFaire%3C/text%3E%3C/svg%3E'" />
                    </div>

                    <div class="paper-details">
                      <div class="detail-buttons">
                        <button class="detail-btn" onclick="toggleDetail(this, 'abstract-7')">Abstract</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'cite-7')">Cite</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'links-7')">Links</button>
                      </div>

                      <div id="abstract-7" class="detail-section">
                        <h3>Abstract</h3>
                        <div class="abstract-text">
                          Ensuring fairness in deep neural networks (DNNs) is challenging because biased decision logic is often entangled with model internals. This article presents Faire, a technique to repair discriminatory behavior in DNNs efficiently and effectively — without requiring additional fairness-specific data such as curated discriminatory examples. Inspired by traditional program repair, Faire localizes unfair decision logic within the network and injects synthesized neuron-level conditions to suppress protected-attribute features and promote task-relevant features. Concretely, Faire (1) analyzes neurons to identify which ones encode protected-attribute information versus task information, and (2) inserts condition layers after each hidden layer to penalize biased neurons and amplify non-biased ones. Faire achieves over 99% repair rate and completes the repair process within a few hundred seconds, outperforming prior fairness-repair methods while maintaining utility.
                        </div>
                      </div>

                      <div id="cite-7" class="detail-section">
                        <h3>Citation</h3>
                        <div class="citation-wrapper">
                          <button class="copy-btn" data-copy-target="cite-7-text" onclick="copyCitation(event, this)">📋 Copy</button>
                          <div id="cite-7-text" class="citation-block">
@article{li2023faire,
  title={Faire: Repairing fairness of neural networks via neuron condition synthesis},
  author={Li, Tianlin and Xie, Xiaofei and Wang, Jian and Guo, Qing and Liu, Aishan and Ma, Lei and Liu, Yang},
  journal={ACM Transactions on Software Engineering and Methodology},
  volume={33},
  number={1},
  pages={1--24},
  year={2023},
  publisher={ACM New York, NY}
}
                          </div>
                        </div>
                      </div>

                      <div id="links-7" class="detail-section">
                        <h3>Resources</h3>
                        <div class="paper-links">
                          <a href="#" target="_blank">📄 Paper</a>
                          <a href="#" target="_blank">📚 ACM DL</a>
                        </div>
                      </div>
                    </div>
                  </div>



                  <!-- Paper 7: NPC (Neuron Path Coverage) -->
                  <div class="paper-container">
                    <div class="paper-header" onclick="togglePaper(this)">
                      <div class="paper-info">
                        <div class="paper-title">
                          NPC: Neuron Path Coverage via Characterizing Decision Logic of Deep Neural Networks
                        </div>
                        <div class="paper-authors" onclick="event.stopPropagation();">
                          <a href="#">Xiaofei Xie</a>,
                          <a href="#">Tianlin Li</a>,
                          <a href="https://scholar.google.com/citations?hl=en&user=GAe_mJUAAAAJ"><strong>Jian Wang</strong></a>,
                          <a href="#">Lei Ma</a>,
                          <a href="#">Qing Guo</a>,
                          <a href="#">Felix Juefei-Xu</a>,
                          <a href="#">Yang Liu</a>
                        </div>
                        <div class="venue-row">
                          <div class="paper-venue">
                            ACM Transactions on Software Engineering and Methodology (TOSEM), vol. 31, no. 3, article 47, April 2022
                          </div>
                          <span class="expand-icon">▼</span>
                        </div>
                        <div class="paper-short-desc">
                          NPC models a DNN’s internal decision logic as a “decision graph,” analogous to a control flow graph in traditional software, and defines new path coverage criteria to evaluate test adequacy. Higher neuron path coverage correlates with error exposure (natural and adversarial) and with output impartiality.
                        </div>
                      </div>
                    </div>

                    <div class="paper-thumbnail">
                      <img src="images/npc.png"
                          alt="Neuron Path Coverage thumbnail"
                          onerror="this.src='data:image/svg+xml,%3Csvg xmlns=\'http://www.w3.org/2000/svg\' width=\'160\' height=\'120\'%3E%3Crect fill=\'%23ddd\' width=\'160\' height=\'120\'/%3E%3Ctext x=\'50%25\' y=\'50%25\' text-anchor=\'middle\' dy=\'.3em\' fill=\'%23999\'%3ENPC%3C/text%3E%3C/svg%3E'" />
                    </div>

                    <div class="paper-details">
                      <div class="detail-buttons">
                        <button class="detail-btn" onclick="toggleDetail(this, 'abstract-8')">Abstract</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'cite-8')">Cite</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'links-8')">Links</button>
                      </div>

                      <div id="abstract-8" class="detail-section">
                        <h3>Abstract</h3>
                        <div class="abstract-text">
                          This article introduces Neuron Path Coverage (NPC), a set of interpretable test coverage criteria for deep neural networks (DNNs). Analogous to traditional program analysis, the approach first constructs a decision graph from a DNN by interpreting neuron behaviors; each path in this graph corresponds to a particular decision logic of the network. From this graph, two path coverage criteria are defined to measure how thoroughly a test suite exercises the network’s decision behaviors. Large-scale experiments demonstrate that (1) these decision paths effectively capture how DNNs make predictions, and (2) higher NPC correlates with both the ability to surface natural and adversarial errors and the impartiality of the model’s outputs.
                        </div>
                      </div>

                      <div id="cite-8" class="detail-section">
                        <h3>Citation</h3>
                        <div class="citation-wrapper">
                          <button class="copy-btn" data-copy-target="cite-8-text" onclick="copyCitation(event, this)">📋 Copy</button>
                          <div id="cite-8-text" class="citation-block">
@article{xie2022npc,
  title={Npc: N euron p ath c overage via characterizing decision logic of deep neural networks},
  author={Xie, Xiaofei and Li, Tianlin and Wang, Jian and Ma, Lei and Guo, Qing and Juefei-Xu, Felix and Liu, Yang},
  journal={ACM Transactions on Software Engineering and Methodology (TOSEM)},
  volume={31},
  number={3},
  pages={1--27},
  year={2022},
  publisher={ACM New York, NY}
}
                          </div>
                        </div>
                      </div>

                      <div id="links-8" class="detail-section">
                        <h3>Resources</h3>
                        <div class="paper-links">
                          <a href="#" target="_blank">📄 Paper</a>
                          <a href="#" target="_blank">📚 ACM DL</a>
                        </div>
                      </div>
                    </div>
                  </div>



                  <!-- Paper 8: ICML -->
                  <div class="paper-container">
                    <div class="paper-header" onclick="togglePaper(this)">
                      <div class="paper-info">
                        <div class="paper-title">Automatic RNN Repair via Model-based Analysis</div>
                        <div class="paper-authors" onclick="event.stopPropagation();">
                          <a href="#">Xiaofei Xie</a>,
                          <a href="#">Wenbo Guo</a>,
                          <a href="#">Lei Ma</a>,
                          <a href="#">Wei Le</a>,
                          <a href="https://scholar.google.com/citations?hl=en&user=GAe_mJUAAAAJ"><strong>Jian Wang</strong></a>,
                          <a href="#">Linjun Zhou</a>,
                          <a href="#">Yang Liu</a>,
                          <a href="#">Xinyu Xing</a>
                        </div>
                        <div class="venue-row">
                          <div class="paper-venue">
                            International Conference on Machine Learning (ICML), 2021
                          </div>
                          <span class="expand-icon">▼</span>
                        </div>
                        <div class="paper-short-desc">
                          A lightweight model-based influence analysis approach to understand and repair incorrect behaviors in RNNs using automaton-based feature extraction.
                        </div>
                      </div>
                    </div>
                    
                    <div class="paper-thumbnail">
                      <img src="images/ICML2021_repair_v2.png" alt="ICML 2021 paper thumbnail" />
                    </div>
                    
                    <div class="paper-details">
                      <div class="detail-buttons">
                        <button class="detail-btn" onclick="toggleDetail(this, 'abstract-9')">Abstract</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'cite-9')">Cite</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'links-9')">Links</button>
                      </div>
                      
                      <div id="abstract-9" class="detail-section">
                        <h3>Abstract</h3>
                        <div class="abstract-text">
                          We propose a lightweight model-based influence analysis to help understand and repair incorrect behaviors of an RNN. Specifically, we build an automaton to enable high-quality feature extraction and to characterize the stateful and statistical behaviors of an RNN over all training data.
                        </div>
                      </div>
                      
                      <div id="cite-9" class="detail-section">
                        <h3>Citation</h3>
                        <div class="citation-wrapper">
                          <button class="copy-btn" data-copy-target="cite-9-text" onclick="copyCitation(event, this)">📋 Copy</button>
                          <div id="cite-9-text" class="citation-block">
@inproceedings{xie2021automatic,
  title={Automatic RNN Repair via Model-based Analysis},
  author={Xie, Xiaofei and Guo, Wenbo and Ma, Lei and Le, Wei and Wang, Jian and Zhou, Linjun and Liu, Yang and Xing, Xinyu},
  booktitle={International Conference on Machine Learning},
  year={2021}
}
                          </div>
                        </div>
                      </div>
                      
                      <div id="links-9" class="detail-section">
                        <h3>Resources</h3>
                        <div class="paper-links">
                          <a href="http://proceedings.mlr.press/v139/xie21b.html" target="_blank">📄 Paper</a>
                          <a href="http://proceedings.mlr.press/v139/xie21b/xie21b.pdf" target="_blank">📥 PDF</a>
                          <a href="https://icml.cc/Conferences/2021/Schedule?showEvent=8766" target="_blank">🎯 Poster</a>
                        </div>
                      </div>
                    </div>
                  </div>

                  <!-- Paper 9: NeurIPS -->
                  <div class="paper-container">
                    <div class="paper-header" onclick="togglePaper(this)">
                      <div class="paper-info">
                        <div class="paper-title">Watch out! Motion is Blurring the Vision of Your Deep Neural Networks</div>
                        <div class="paper-authors" onclick="event.stopPropagation();">
                          <a href="#">Qing Guo</a>,
                          <a href="#">Felix Juefei-Xu</a>,
                          <a href="#">Xiaofei Xie</a>,
                          <a href="#">Lei Ma</a>,
                          <a href="https://scholar.google.com/citations?hl=en&user=GAe_mJUAAAAJ"><strong>Jian Wang</strong></a>,
                          <a href="#">Bing Yu</a>,
                          <a href="#">Wei Feng</a>,
                          <a href="#">Yang Liu</a>
                        </div>
                        <div class="venue-row">
                          <div class="paper-venue">
                            Advances in Neural Information Processing Systems (NeurIPS), 2020
                          </div>
                          <span class="expand-icon">▼</span>
                        </div>
                        <div class="paper-short-desc">
                          Introducing a motion-based adversarial blur attack (ABBA) that generates visually natural motion-blurred adversarial examples to fool DNNs.
                        </div>
                      </div>
                    </div>
                    
                    <div class="paper-thumbnail">
                      <img src="images/abba_logo.png" alt="NeurIPS 2020 paper thumbnail" />
                    </div>
                    
                    <div class="paper-details">
                      <div class="detail-buttons">
                        <button class="detail-btn" onclick="toggleDetail(this, 'abstract-10')">Abstract</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'cite-10')">Cite</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'links-10')">Links</button>
                      </div>
                      
                      <div id="abstract-10" class="detail-section">
                        <h3>Abstract</h3>
                        <div class="abstract-text">
                          We introduce a motion-based adversarial blur attack (ABBA) that can generate visually natural motion-blurred adversarial examples. Unlike traditional adversarial attacks that add imperceptible noise, our method exploits the natural motion blur phenomenon to create adversarial perturbations that are more realistic and harder to detect.
                        </div>
                      </div>
                      
                      <div id="cite-10" class="detail-section">
                        <h3>Citation</h3>
                        <div class="citation-wrapper">
                          <button class="copy-btn" data-copy-target="cite-10-text" onclick="copyCitation(event, this)">📋 Copy</button>
                          <div id="cite-10-text" class="citation-block">
@inproceedings{guo2020watch,
  title={Watch out! Motion is Blurring the Vision of Your Deep Neural Networks},
  author={Guo, Qing and Juefei-Xu, Felix and Xie, Xiaofei and Ma, Lei and Wang, Jian and Yu, Bing and Feng, Wei and Liu, Yang},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}
                          </div>
                        </div>
                      </div>
                      
                      <div id="links-10" class="detail-section">
                        <h3>Resources</h3>
                        <div class="paper-links">
                          <a href="data/felix_neurips20_abba.pdf" target="_blank">📄 Paper</a>
                          <a href="http://arxiv.org/abs/2002.03500" target="_blank">📚 arXiv</a>
                        </div>
                      </div>
                    </div>
                  </div>

                  <!-- Paper 10: IJCAI -->
                  <div class="paper-container">
                    <div class="paper-header" onclick="togglePaper(this)">
                      <div class="paper-info">
                        <div class="paper-title">FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized Fake Faces</div>
                        <div class="paper-authors" onclick="event.stopPropagation();">
                          <a href="#">Run Wang</a>,
                          <a href="#">Felix Juefei-Xu</a>,
                          <a href="#">Lei Ma</a>,
                          <a href="#">Xiaofei Xie</a>,
                          <a href="#">Yihao Huang</a>,
                          <a href="https://scholar.google.com/citations?hl=en&user=GAe_mJUAAAAJ"><strong>Jian Wang</strong></a>,
                          <a href="#">Yang Liu</a>
                        </div>
                        <div class="venue-row">
                          <div class="paper-venue">
                            International Joint Conference on Artificial Intelligence (IJCAI), 2020
                          </div>
                          <span class="expand-icon">▼</span>
                        </div>
                        <div class="paper-short-desc">
                          Detecting AI-synthesized fake faces by monitoring neuron behavior and analyzing layer-by-layer activation patterns to capture subtle features.
                        </div>
                      </div>
                    </div>
                    
                    <div class="paper-thumbnail">
                      <img src="images/fakespotter_logo.png" alt="IJCAI 2020 paper thumbnail" />
                    </div>
                    
                    <div class="paper-details">
                      <div class="detail-buttons">
                        <button class="detail-btn" onclick="toggleDetail(this, 'abstract-11')">Abstract</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'cite-11')">Cite</button>
                        <button class="detail-btn" onclick="toggleDetail(this, 'links-11')">Links</button>
                      </div>
                      
                      <div id="abstract-11" class="detail-section">
                        <h3>Abstract</h3>
                        <div class="abstract-text">
                          Monitoring neuron behavior can help detect AI-synthesized fake faces, since layer-by-layer activation patterns may capture subtle features important for the detector. Our approach, FakeSpotter, provides a simple yet robust baseline for detecting deepfakes by analyzing the internal representations of neural networks.
                        </div>
                      </div>
                      
                      <div id="cite-11" class="detail-section">
                        <h3>Citation</h3>
                        <div class="citation-wrapper">
                          <button class="copy-btn" data-copy-target="cite-11-text" onclick="copyCitation(event, this)">📋 Copy</button>
                          <div id="cite-11-text" class="citation-block">
@inproceedings{wang2020fakespotter,
  title={FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized Fake Faces},
  author={Wang, Run and Juefei-Xu, Felix and Ma, Lei and Xie, Xiaofei and Huang, Yihao and Wang, Jian and Liu, Yang},
  booktitle={International Joint Conference on Artificial Intelligence},
  year={2020}
}
                          </div>
                        </div>
                      </div>
                      
                      <div id="links-11" class="detail-section">
                        <h3>Resources</h3>
                        <div class="paper-links">
                          <a href="data/felix_ijcai20_fakespotter.pdf" target="_blank">📄 Paper</a>
                          <a href="http://arxiv.org/abs/1909.06122" target="_blank">📚 arXiv</a>
                          <a href="https://syncedreview.com/2019/09/23/ai-vs-ai-fakespotter-studies-neurons-to-bust-deepfakes/" target="_blank">📰 Media Coverage</a>
                        </div>
                      </div>
                    </div>
                  </div>

                </td>
              </tr>
            </tbody>
          </table>

          <!-- Engineering -->
          <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:20px;">
                  <h2>Engineering</h2>
                </td>
              </tr>
            </tbody>
          </table>

          <ul>
            <li>
              <strong><a href="https://xiaofeixie.bitbucket.io/publications/">Singapore Management University(SMU)</a></strong> —
              Research Assistant (code Intelligence and Code LLM security) (2023-Aug ~ )
            </li>
            <li>
              <strong><a href="https://liyiweb.com/teaching/">Nanyang Technological University (NTU)</a></strong> —
              Research Assistant (DL and LLM security), Singapore (2019-Dec ~ 2023-Aug )
            </li>
            <li>
              <strong><a href="https://www.hkex.com.hk/Market-Data/Securities-Prices/Equities/Equities-Quote?sym=1810&sc_lang=en">Xiaomi Group</a></strong> —
              Xiaomi AI Lab (trained portrait image DL generator), Beijing, China (2017—2019)
            </li>
            <li>
              <strong><a href="https://www.sec.gov/Archives/edgar/data/1525494/000104746913009364/a2216693zf-1.htm">58 Inc.</a></strong> —
              Backend Engineer (Middleware), 58 Group, Beijing, China (2011—2017)
            </li>
            <li>
              <strong><a href="https://www.sec.gov/Archives/edgar/data/1329099/000119312505159073/d424b4.htm">Baidu, Inc.</a></strong> —
              Data Engineer (Intern), Beijing, China (2011)
            </li>
          </ul>

          <!-- Footer -->
          <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:0;">
                  <br />
                  <p style="text-align:right;font-size:small;">
                    I forked this source code from
                    <a href="https://github.com/jonbarron/website">jonbarron</a> and
                    <a href="http://xujuefei.com/">xujuefei</a>.
                    Also consider
                    <a href="https://leonidk.com/">Leonid Keselman</a>'s
                    <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                  </p>
                </td>
              </tr>
              <tr>
                <td style="padding:0;">
                  <br />
                  <p style="text-align:right;font-size:small;">
                    ICP-1900352-1 <a href="https://beian.miit.gov.cn">link</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Optional counter (kept but commented script) -->
          <table width="100" height="100" align="center" border="0" cellspacing="0" cellpadding="2" style="margin:0 auto;">
            <tbody>
              <tr>
                <td align="center">
                  <p style="text-align:center;width:100%;">
                    <!-- <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=wSB3PmmkU6UW_4U3Vv0hggqAXeExp_GJZ-4FYY2piR8"></script> -->
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
    </tbody>
  </table>

  <script>
    function togglePaper(header) {
      const container = header.closest('.paper-container');
      const allContainers = document.querySelectorAll('.paper-container');
      
      // Close all other papers
      allContainers.forEach(c => {
        if (c !== container) {
          c.classList.remove('expanded');
          // Hide all detail sections in other papers
          const sections = c.querySelectorAll('.detail-section');
          sections.forEach(s => s.classList.remove('show'));
          const buttons = c.querySelectorAll('.detail-btn');
          buttons.forEach(b => b.classList.remove('active'));
        }
      });
      
      // Toggle current paper
      container.classList.toggle('expanded');
      
      // If closing, hide all detail sections
      if (!container.classList.contains('expanded')) {
        const sections = container.querySelectorAll('.detail-section');
        sections.forEach(s => s.classList.remove('show'));
        const buttons = container.querySelectorAll('.detail-btn');
        buttons.forEach(b => b.classList.remove('active'));
      }
    }
    
    function toggleDetail(button, sectionId) {
      event.stopPropagation();
      
      const section = document.getElementById(sectionId);
      const container = button.closest('.paper-container');
      const allButtons = container.querySelectorAll('.detail-btn');
      const allSections = container.querySelectorAll('.detail-section');
      
      // If clicking the same button, toggle it
      if (button.classList.contains('active')) {
        button.classList.remove('active');
        section.classList.remove('show');
      } else {
        // Remove active from all buttons and hide all sections
        allButtons.forEach(b => b.classList.remove('active'));
        allSections.forEach(s => s.classList.remove('show'));
        
        // Show selected section
        button.classList.add('active');
        section.classList.add('show');
      }
    }

    function copyCitation(e, btnEl) {
      e.stopPropagation(); // don't collapse sections
      const targetId = btnEl.getAttribute('data-copy-target');
      if (!targetId) return;
      const block = document.getElementById(targetId);
      if (!block) return;
      
      // Get raw text (not HTML)
      const text = block.innerText;

      // Copy to clipboard using Clipboard API (modern browsers)
      navigator.clipboard.writeText(text)
        .then(() => {
          // Give visual feedback
          btnEl.classList.add('copied');
          const original = btnEl.innerHTML;
          btnEl.innerHTML = "✔ Copied";
          setTimeout(() => {
            btnEl.classList.remove('copied');
            btnEl.innerHTML = original;
          }, 2000);
        })
        .catch(() => {
          // fallback for very old browsers
          const tempTextArea = document.createElement('textarea');
          tempTextArea.value = text;
          document.body.appendChild(tempTextArea);
          tempTextArea.select();
          try {
            document.execCommand('copy');
            btnEl.classList.add('copied');
            const original = btnEl.innerHTML;
            btnEl.innerHTML = "✔ Copied";
            setTimeout(() => {
              btnEl.classList.remove('copied');
              btnEl.innerHTML = original;
            }, 2000);
          } catch (err) {
            console.warn('Copy failed', err);
          }
          document.body.removeChild(tempTextArea);
        });
    }
  </script>
</body>
</html>


